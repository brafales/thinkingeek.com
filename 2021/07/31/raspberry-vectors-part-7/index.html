<!DOCTYPE html>
<html lang="en">

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  
  
  <title>Fun with vectors in the Raspberry Pi 1 - Part 7</title>
  <meta name="description" content="We finished the last installment of this series mentioning that the compiler cannot copy, load or store a vector. Today we will address this.">
  

  <link rel="stylesheet" href="/assets/main.css">
  <link rel="canonical" href="https://thinkingeek.com/2021/07/31/raspberry-vectors-part-7/">
  
  
  <link rel="alternate" type="application/rss+xml" title="Think In Geek" href="https://thinkingeek.com/feed.xml">

  

  
  <meta property="og:title" content="Fun with vectors in the Raspberry Pi 1 - Part 7">
  <meta property="og:site_name" content="Think In Geek">
  <meta property="og:url" content="https://thinkingeek.com/2021/07/31/raspberry-vectors-part-7/">
  <meta property="og:description" content="We finished the last installment of this series mentioning that the compiler cannot copy, load or store a vector. Today we will address this.">
  
  
  <meta name="twitter:card" content="summary">
  
  <meta name="twitter:title" content="Fun with vectors in the Raspberry Pi 1 - Part 7">
  <meta name="twitter:description" content="We finished the last installment of this series mentioning that the compiler cannot copy, load or store a vector. Today we will address this.">
  
  

  <link rel="dns-prefetch" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.googleapis.com" crossorigin>
<link href='https://fonts.googleapis.com/css?family=Source+Sans+Pro:400,400italic,700,700italic' rel='stylesheet' type='text/css'>
<link href="https://fonts.googleapis.com/css?family=Fira+Mono:400,700" rel="stylesheet">

  

</head>


  <body>

    <header class="site-header">

  <div class="wrapper">

      <span class="site-title"><a href="/">Think In Geek</a> | </span>
      <span class="site-slogan">In geek we trust</span>

    <nav class="site-nav"><a class="page-link" href="/arm-assembler-raspberry-pi/">Arm Assembler Raspberry Pi</a><a class="page-link" href="/gcc-tiny/">GCC tiny</a><a class="page-link" href="/author/brafales/">Posts by Bernat Ràfales</a><a class="page-link" href="/archives/">Archives</a></nav>

  </div>

</header>


    <main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    
      <h1 class="post-title" itemprop="name headline">Fun with vectors in the Raspberry Pi 1 - Part 7</h1>
    
    <p class="post-meta"><time datetime="2021-07-31T08:59:00+00:00" itemprop="datePublished">Jul 31, 2021</time> • <span itemprop="author" itemscope itemtype="http://schema.org/Person"><span itemprop="name">Roger Ferrer Ibáñez</span></span> • <a href="/categories/vectors/">vectors</a>, <a href="/categories/raspberry-pi-1/">raspberry pi 1</a>, <a href="/categories/llvm/">llvm</a>, <a href="/categories/compilers/">compilers</a>, <a href="/categories/arm/">arm</a></p>
  </header>

  <div class="post-content" itemprop="articleBody">
    <p>We finished the last installment of this series mentioning that the compiler
cannot copy, load or store a vector. Today we will address this.</p>

<!--more-->

<h2>Spill code and copies</h2>

<p>LLVM, like many other compiler infrastructures, uses the concept of <em>virtual
register</em>. Virtual registers are abstractions over the <em>physical</em> registers
available in an architecture (note to architects: <em>physical</em> registers in
compilers means <em>architectural</em> registers, not <em>renaming</em> registers).</p>

<p>During code generation in Machine IR (MIR), LLVM can combine the concept of
virtual register with that of Static Single Assignment (SSA). This is very
convenient for optimisations and transformations that happen on MIR.</p>

<p>The number of virtual registers is unbounded. However the number of physical
registers available in a register-based architecture is finite. There is a
process called <em>register allocation</em> that assigns a physical register to every
virtual registers. Due to the finiteness of the physical registers, register
allocation may run out of available physical registers. In these cases the
compiler has to emit <em>spill code</em> in which a physical register already in use
is preserved temporarily in some other memory, typically the stack of the
program. The details are a bit complex at this point but we only need to
know that saving a register on that memory is typically called <em>spill</em> and
restoring it afterwards is called a <em>reload</em>.</p>

<p>There is another case where LLVM will emit spill code. Calling conventions can
require registers be preserved around function calls or upon entry/exit of a
function. While these are not considered spill code in the traditional sense,
LLVM combines the two cases.</p>

<p>Before register allocation can run, however, SSA form must be removed. The
fundamentals of SSA is that every virtual register in the program must be
defined only once and can be used many times. However we quickly run into the
issue that the value of a virtual register may depend on control flow. Consider
a program thas uses a variable whose value may have conditionally changed in an
<code class="language-plaintext highlighter-rouge">if</code> statement. SSA represents those <em>converging</em> values due to control flow
using <em>phi</em> instructions. Phi instructions are not executable, they are an
abstraction, and must be removed.  Without going into much detail, when
removing phi operations, the compiler will introduce copies to implement the
semantics of the phi instruction. It may not be obvious, but it is precisely
this insertion of copies what destroys the SSA property of the code: a same
virtual register will be defined by different instructions.</p>

<h2>Load and store</h2>

<p>There are a couple of functions <code class="language-plaintext highlighter-rouge">storeRegToStackSlot</code> and
<code class="language-plaintext highlighter-rouge">loadRegFromStackSlot</code> in <code class="language-plaintext highlighter-rouge">llvm/lib/Target/ARM/ARMBaseInstrInfo.cpp</code>
responsible for emitting the machine instruction used to spill and reload
respectively. One issue here is that only one instruction is allowed due to
expectations in the spilling functions used by the register allocator.</p>

<p>Ideally we would like to use <code class="language-plaintext highlighter-rouge">vstmdia</code> / <code class="language-plaintext highlighter-rouge">vstmsia</code> for double and floating
point stores respectively.  Similarly <code class="language-plaintext highlighter-rouge">vldmdia</code> / <code class="language-plaintext highlighter-rouge">vldmsia</code> for loads. However
these instructions expect a contiguous range of registers. We allow
representing vectors over non-contiguous registers wrapping around in the same
vector bank (say <code class="language-plaintext highlighter-rouge">d7</code> and <code class="language-plaintext highlighter-rouge">d4</code>). Also LLVM comes with a limitation here: we
must use a single instruction for the spill and reload.</p>

<p>We can address this, again, using pseudo-instructions that we will lower in the
best way possible. First we will define two pseudo-instructions, one for each
vector type, <code class="language-plaintext highlighter-rouge">VFPSPILL</code> and <code class="language-plaintext highlighter-rouge">VFPRELOAD</code>.</p>

<figure class="highlight"><figcaption>llvm/lib/Target/ARM/ARMInstrVFP.td</figcaption><pre><code class="language-diff" data-lang="diff"><span class="p">@@ -2934,6 +2934,34 @@</span> def VFPSETLEN : PseudoInst&lt;(outs GPR:$scratch1, GPRnopc:$scratch2),
                            IIC_fpSTAT, []&gt;,
                           Requires&lt;[HasVFP2]&gt;;
 
<span class="gi">+// Spill and reload helpers.
+let AM = AddrMode4 in {
+let hasNoSchedulingInfo = 1,
+    mayLoad = 0,
+    mayStore = 1 in
+def VFPSPILLDx2 : PseudoInst&lt;(outs), (ins DPRx2:$Dm, GPR:$Rn),
+                             IIC_fpStore64, []&gt;,
+                            Requires&lt;[HasVFP2]&gt;;
+let hasNoSchedulingInfo = 1,
+    mayLoad = 1,
+    mayStore = 0 in
+def VFPRELOADDx2 : PseudoInst&lt;(outs DPRx2:$Dd), (ins GPR:$Rn),
+                              IIC_fpLoad64, []&gt;,
+                             Requires&lt;[HasVFP2]&gt;;
+let hasNoSchedulingInfo = 1,
+    mayLoad = 0,
+    mayStore = 1 in
+def VFPSPILLSx4 : PseudoInst&lt;(outs), (ins SPRx4:$Dm, GPR:$Rn),
+                             IIC_fpStore64, []&gt;,
+                            Requires&lt;[HasVFP2]&gt;;
+let hasNoSchedulingInfo = 1,
+    mayLoad = 1,
+    mayStore = 0 in
+def VFPRELOADSx4 : PseudoInst&lt;(outs SPRx4:$Dd), (ins GPR:$Rn),
+                              IIC_fpLoad64, []&gt;,
+                             Requires&lt;[HasVFP2]&gt;;
+}
+
</span> // Computation: LEN=2
 let usesCustomInserter = 1 in {
 let VectorLength = 0b001 in {</code></pre></figure>

<p>Now we can extend <code class="language-plaintext highlighter-rouge">storeRegToStackSlot</code> and <code class="language-plaintext highlighter-rouge">loadRegFromStackSlot</code> so they
emit these instructions when we have to store/load a register of the <code class="language-plaintext highlighter-rouge">DPRx2</code> or
<code class="language-plaintext highlighter-rouge">SPRx4</code> register classes.</p>

<figure class="highlight"><figcaption>llvm/lib/Target/ARM/ARMBaseInstrInfo.cpp</figcaption><pre><code class="language-diff" data-lang="diff"><span class="p">@@ -1213,6 +1223,18 @@</span> storeRegToStackSlot(MachineBasicBlock &amp;MBB, MachineBasicBlock::iterator I,
           .addImm(0)
           .addMemOperand(MMO);
         addUnpredicatedMveVpredNOp(MIB);
<span class="gi">+      } else if (ARM::DPRx2RegClass.hasSubClassEq(RC) &amp;&amp;
+                 Subtarget.hasVFP2Base()) {
+        BuildMI(MBB, I, DebugLoc(), get(ARM::VFPSPILLDx2))
+            .addReg(SrcReg, getKillRegState(isKill))
+            .addFrameIndex(FI)
+            .addMemOperand(MMO);
+      } else if (ARM::SPRx4RegClass.hasSubClassEq(RC) &amp;&amp;
+                 Subtarget.hasVFP2Base()) {
+        BuildMI(MBB, I, DebugLoc(), get(ARM::VFPSPILLSx4))
+            .addReg(SrcReg, getKillRegState(isKill))
+            .addFrameIndex(FI)
+            .addMemOperand(MMO);
</span>       } else
         llvm_unreachable("Unknown reg class!");
       break;
<span class="p">@@ -1451,6 +1473,16 @@</span> loadRegFromStackSlot(MachineBasicBlock &amp;MBB, MachineBasicBlock::iterator I,
         .addImm(0)
         .addMemOperand(MMO);
       addUnpredicatedMveVpredNOp(MIB);
<span class="gi">+    } else if (ARM::DPRx2RegClass.hasSubClassEq(RC) &amp;&amp;
+               Subtarget.hasVFP2Base()) {
+      BuildMI(MBB, I, DL, get(ARM::VFPRELOADDx2), DestReg)
+          .addFrameIndex(FI)
+          .addMemOperand(MMO);
+    } else if (ARM::SPRx4RegClass.hasSubClassEq(RC) &amp;&amp;
+               Subtarget.hasVFP2Base()) {
+      BuildMI(MBB, I, DL, get(ARM::VFPRELOADSx4), DestReg)
+          .addFrameIndex(FI)
+          .addMemOperand(MMO);
</span>     } else
       llvm_unreachable("Unknown reg class!");
     break;</code></pre></figure>

<p>As you can see, we basically encapsulate the destination register along with
the abstraction of the stack, called <em>frame index</em> in LLVM. Finally we make
sure the memory operands are there: these are extra bits of information LLVM
can use to reason about memory accesses.</p>

<h3>Lowering</h3>

<p>Those pseudo instructions will need some lowering. Again this happens in
<code class="language-plaintext highlighter-rouge">ARMExpandPseudoInsts.cpp</code>.</p>

<p>Our strategy will be fairly simple. If we can use the multiple memory access
instructions <code class="language-plaintext highlighter-rouge">vldmdia</code>/  <code class="language-plaintext highlighter-rouge">vldmsia</code> / <code class="language-plaintext highlighter-rouge">vstmdia</code> / <code class="language-plaintext highlighter-rouge">vstmsia</code> we will use them. If
we cannot we will emit a bunch of simple loads and stores.</p>

<p>Note that for doubles this would be enough because vectors only have two
elements. For vectors of floats, though, there are more cases: a) all four
registers may be consecutive (e.g.: <code class="language-plaintext highlighter-rouge">s8</code>, <code class="language-plaintext highlighter-rouge">s9</code>, <code class="language-plaintext highlighter-rouge">s10</code>, <code class="language-plaintext highlighter-rouge">s11</code>) three are
consecutive (e.g.  <code class="language-plaintext highlighter-rouge">s13</code>, <code class="language-plaintext highlighter-rouge">s14</code>, <code class="language-plaintext highlighter-rouge">s15</code>, <code class="language-plaintext highlighter-rouge">s8</code>), c) two are consecutive and the
two other are consecutive but not respect to the other two (e.g. <code class="language-plaintext highlighter-rouge">s14</code>, <code class="language-plaintext highlighter-rouge">s15</code>,
<code class="language-plaintext highlighter-rouge">s8</code>, <code class="language-plaintext highlighter-rouge">s9</code>).  For simplicity we will ignore those cases but they are not too
conceptually difficult to implement.</p>

<p>We will see the implementation for double vectors, float vectors would be
implemented in a similar way. We first check if the registers are
consecutive. If they are then we can use <code class="language-plaintext highlighter-rouge">vldmdia</code> or <code class="language-plaintext highlighter-rouge">vstmdia</code>.</p>

<p>If they are not consecutive then we need to emit explicit loads and stores
<code class="language-plaintext highlighter-rouge">vldrd</code> and <code class="language-plaintext highlighter-rouge">vstrd</code>. Some complexity comes in the form of computing the right
memory operand for the new loads and stores as we need to adjust the right
offset and size of data being accessed. This is encapsulated in convenient
lambdas <code class="language-plaintext highlighter-rouge">EmitLoad</code> and <code class="language-plaintext highlighter-rouge">EmitStore</code>. One important thing to note is that <code class="language-plaintext highlighter-rouge">vldrd</code>
and <code class="language-plaintext highlighter-rouge">vstrd</code> instructions expect an offset operand in units of 4 bytes, hence
<code class="language-plaintext highlighter-rouge">.addImm(Offset / 4)</code>. In the memory operand though, the offset is specified in
bytes.</p>

<figure class="highlight"><figcaption>llvm/lib/Target/ARM/ARMExpandPseudoInsts.cpp</figcaption><pre><code class="language-diff" data-lang="diff"><span class="p">@@ -3026,6 +3026,173 @@</span> bool ARMExpandPseudo::ExpandMI(MachineBasicBlock &amp;MBB,
       MI.eraseFromParent();
       return true;
     }
<span class="gi">+    case ARM::VFPSPILLDx2: {
+      Register Src = MI.getOperand(0).getReg();
+      const MachineOperand &amp;Addr = MI.getOperand(1);
+      DebugLoc dl = MI.getDebugLoc();
+
+      Register Src0 = TRI-&gt;getSubReg(Src, ARM::dsub_len2_0);
+      Register Src1 = TRI-&gt;getSubReg(Src, ARM::dsub_len2_1);
+
+      if (Src0 + 1 == Src1) {
+        // Use vstmdia.
+        BuildMI(MBB, MBBI, dl, TII-&gt;get(ARM::VSTMDIA))
+            .add(Addr)
+            .add(predOps(ARMCC::AL))
+            .cloneMemRefs(MI)
+            .addReg(Src0, getKillRegState(MI.getOperand(1).isKill()))
+            .addReg(Src1);
+      } else {
+        assert(MI.hasOneMemOperand() &amp;&amp; "Need one memoperand");
+        const MachineMemOperand *MMO = *MI.memoperands_begin();
+        MachineFunction *MF = MBB.getParent();
+
+        auto EmitStore = [&amp;](Register RegSrc, uint64_t Offset) {
+          MachineMemOperand *NewMMO = MF-&gt;getMachineMemOperand(
+              MMO-&gt;getPointerInfo().getWithOffset(Offset),
+              MachineMemOperand::MOStore, MMO-&gt;getSize() / 2, MMO-&gt;getAlign());
+          BuildMI(MBB, MBBI, dl, TII-&gt;get(ARM::VSTRD))
+              .addReg(RegSrc)
+              .add(Addr)
+              .addImm(Offset / 4)
+              .addMemOperand(NewMMO)
+              .add(predOps(ARMCC::AL));
+        };
+
+        EmitStore(Src0, 0);
+        EmitStore(Src1, 8);
+      }
+      MI.eraseFromParent();
+      return true;
+    }
+    case ARM::VFPRELOADDx2: {
+      Register Dest = MI.getOperand(0).getReg();
+      const MachineOperand &amp;Addr = MI.getOperand(1);
+      DebugLoc dl = MI.getDebugLoc();
+
+      Register Dest0 = TRI-&gt;getSubReg(Dest, ARM::dsub_len2_0);
+      Register Dest1 = TRI-&gt;getSubReg(Dest, ARM::dsub_len2_1);
+
+      if (Dest0 + 1 == Dest1) {
+        // Use vldmdia.
+        BuildMI(MBB, MBBI, dl, TII-&gt;get(ARM::VLDMDIA))
+            .add(Addr)
+            .cloneMemRefs(MI)
+            .add(predOps(ARMCC::AL))
+            .addReg(Dest0, RegState::DefineNoRead)
+            .addReg(Dest1, RegState::DefineNoRead);
+      } else {
+        assert(MI.hasOneMemOperand() &amp;&amp; "Need one memoperand");
+        const MachineMemOperand *MMO = *MI.memoperands_begin();
+        MachineFunction *MF = MBB.getParent();
+
+        auto EmitLoad = [&amp;](Register RegDst, uint64_t Offset) {
+          MachineMemOperand *NewMMO = MF-&gt;getMachineMemOperand(
+              MMO-&gt;getPointerInfo().getWithOffset(Offset),
+              MachineMemOperand::MOLoad, MMO-&gt;getSize() / 2, MMO-&gt;getAlign());
+          BuildMI(MBB, MBBI, dl, TII-&gt;get(ARM::VLDRD), Dest0)
+              .add(Addr)
+              .addImm(Offset / 4)
+              .addMemOperand(NewMMO)
+              .add(predOps(ARMCC::AL));
+        };
+
+        EmitLoad(Dest0, 0);
+        EmitLoad(Dest1, 8);
+      }
+      MI.eraseFromParent();
+      return true;
+    }
</span>   }
 }</code></pre></figure>

<h3>Results</h3>

<p>Let’s see this in action. In the last installment we said that doing a call
while vectors were live caused the compiler to crash because
it does not know how to spill and reload the vectors.</p>

<p>An example of LLVM IR that triggers this behaviour is this one:</p>

<figure class="highlight"><figcaption>test.ll</figcaption><pre><code class="language-llvm" data-lang="llvm"><span class="k">declare</span> <span class="kt">void</span> <span class="vg">@foo</span><span class="p">(</span><span class="kt">i32</span> <span class="nv">%a</span><span class="p">,</span> <span class="kt">i32</span> <span class="nv">%b</span><span class="p">)</span>

<span class="k">define</span> <span class="kt">void</span> <span class="vg">@test_vec</span><span class="p">(&lt;</span><span class="m">2</span> <span class="p">x</span> <span class="kt">double</span><span class="p">&gt;</span> <span class="p">*</span><span class="nv">%pa</span><span class="p">,</span> <span class="p">&lt;</span><span class="m">2</span> <span class="p">x</span> <span class="kt">double</span><span class="p">&gt;</span> <span class="p">*</span><span class="nv">%pb</span><span class="p">,</span> <span class="p">&lt;</span><span class="m">2</span> <span class="p">x</span> <span class="kt">double</span><span class="p">&gt;</span> <span class="p">*</span><span class="nv">%pc</span><span class="p">)</span> <span class="p">{</span>
  <span class="nv">%a</span> <span class="p">=</span> <span class="k">load</span> <span class="p">&lt;</span><span class="m">2</span> <span class="p">x</span> <span class="kt">double</span><span class="p">&gt;,</span> <span class="p">&lt;</span><span class="m">2</span> <span class="p">x</span> <span class="kt">double</span><span class="p">&gt;*</span> <span class="nv">%pa</span>
  <span class="nv">%b</span> <span class="p">=</span> <span class="k">load</span> <span class="p">&lt;</span><span class="m">2</span> <span class="p">x</span> <span class="kt">double</span><span class="p">&gt;,</span> <span class="p">&lt;</span><span class="m">2</span> <span class="p">x</span> <span class="kt">double</span><span class="p">&gt;*</span> <span class="nv">%pb</span>
  <span class="k">call</span> <span class="kt">void</span> <span class="vg">@foo</span><span class="p">(</span><span class="kt">i32</span> <span class="m">1</span><span class="p">,</span> <span class="kt">i32</span> <span class="m">3</span><span class="p">)</span>
  <span class="nv">%c</span> <span class="p">=</span> <span class="k">fadd</span> <span class="p">&lt;</span><span class="m">2</span> <span class="p">x</span> <span class="kt">double</span><span class="p">&gt;</span> <span class="nv">%a</span><span class="p">,</span> <span class="nv">%b</span>
  <span class="k">store</span> <span class="p">&lt;</span><span class="m">2</span> <span class="p">x</span> <span class="kt">double</span><span class="p">&gt;</span> <span class="nv">%c</span><span class="p">,</span> <span class="p">&lt;</span><span class="m">2</span> <span class="p">x</span> <span class="kt">double</span><span class="p">&gt;</span> <span class="p">*</span><span class="nv">%pc</span>
  <span class="k">ret</span> <span class="kt">void</span>
<span class="p">}</span></code></pre></figure>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="nv">$ </span>llc <span class="nt">-mtriple</span> armv6kz-unknown-linux-gnu <span class="nt">-mattr</span><span class="o">=</span>+vfp2  <span class="nt">-o</span> - test.ll</code></pre></figure>

<figure class="highlight"><pre><code class="language-asm" data-lang="asm">test_vec:
	.fnstart
@ %bb.0:
	push	{r4, r5, r6, lr}
	sub	sp, sp, #32
	add	lr, sp, #16
	vldmia	r1, {d4, d5}
	mov	r1, #3
	mov	r4, r2
	vstmia	lr, {d4, d5}                    @ 16-byte Spill
	vldmia	r0, {d4, d5}
	mov	r0, #1
	vstmia	sp, {d4, d5}                    @ 16-byte Spill
	bl	foo
	vmrs	r1, fpscr
	mov	r0, #65536
	add	lr, sp, #16
	bic	r1, r1, #458752
	orr	r1, r1, r0
	vmsr	fpscr, r1
	vldmia	lr, {d4, d5}                    @ 16-byte Reload
	vldmia	sp, {d6, d7}                    @ 16-byte Reload
	vadd.f64	d4, d6, d4
	vstmia	r4, {d4, d5}
	vmrs	r1, fpscr
	bic	r1, r1, #458752
	vmsr	fpscr, r1
	add	sp, sp, #32
	pop	{r4, r5, r6, pc}</code></pre></figure>

<p>Here we can see how the compiler explicitly spills and reloads vectors around
the call to <code class="language-plaintext highlighter-rouge">foo</code>. Note that the spills have as source the same pair <code class="language-plaintext highlighter-rouge">d4</code>, <code class="language-plaintext highlighter-rouge">d5</code>
because the compiler does not need another pair in that position. However, the
reloads do have to use different pairs otherwise the addition (<code class="language-plaintext highlighter-rouge">vadd.f64</code>) will
not be possible.</p>

<p>It is a bit difficult to observe the use of <code class="language-plaintext highlighter-rouge">vstrd</code> and <code class="language-plaintext highlighter-rouge">vldrd</code> for the
non-consecutive case. One thing we can do is manually modifying the Machine IR so
it uses <code class="language-plaintext highlighter-rouge">d7</code> and <code class="language-plaintext highlighter-rouge">d4</code> instead of <code class="language-plaintext highlighter-rouge">d4</code>, <code class="language-plaintext highlighter-rouge">d5</code>. To get the Machine IR, we must stop
before finishing the code generation pipeline. A location that seems convenient
is stopping before the <code class="language-plaintext highlighter-rouge">arm-ldst-opt</code> pass, responsible for optimising
several memory accesses into multiple memory accesses.</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="nv">$ </span>llc <span class="nt">-mtriple</span> armv6kz-unknown-linux-gnu <span class="nt">-mattr</span><span class="o">=</span>+vfp2  <span class="nt">-o</span> test.mir <span class="se">\</span>
      <span class="nt">-stop-before</span><span class="o">=</span>arm-ldst-opt</code></pre></figure>

<p>Now we modify the <code class="language-plaintext highlighter-rouge">test.mir</code> file like this</p>

<figure class="highlight"><pre><code class="language-diff" data-lang="diff"><span class="p">@@ -90,23 +90,23 @@</span> body:             |
     $sp = frame-setup SUBri killed $sp, 32, 14 /* CC::al */, $noreg, $noreg
     frame-setup CFI_INSTRUCTION def_cfa_offset 48
     $r4 = MOVr $r2, 14 /* CC::al */, $noreg, $noreg
<span class="gd">-    renamable $d4 = VLDRD renamable $r1, 0, 14 /* CC::al */, $noreg, implicit-def $d4_d5x2 :: (load 8 from %ir.pb)
-    renamable $d5 = VLDRD killed renamable $r1, 2, 14 /* CC::al */, $noreg, implicit killed $d4_d5x2, implicit-def $d4_d5x2 :: (load 8 from %ir.pb + 8)
</span><span class="gi">+    renamable $d7 = VLDRD renamable $r1, 0, 14 /* CC::al */, $noreg, implicit-def $d7_d4x2 :: (load 8 from %ir.pb)
+    renamable $d4 = VLDRD killed renamable $r1, 2, 14 /* CC::al */, $noreg, implicit killed $d7_d4x2, implicit-def $d7_d4x2 :: (load 8 from %ir.pb + 8)
</span>     $lr = ADDri killed $sp, 16, 14 /* CC::al */, $noreg, $noreg
<span class="gd">-    VFPSPILLDx2 killed renamable $d4_d5x2, killed $lr :: (store 16 into %stack.0, align 8)
-    renamable $d4 = VLDRD renamable $r0, 0, 14 /* CC::al */, $noreg, implicit-def $d4_d5x2 :: (load 8 from %ir.pa)
-    renamable $d5 = VLDRD killed renamable $r0, 2, 14 /* CC::al */, $noreg, implicit killed $d4_d5x2, implicit-def $d4_d5x2 :: (load 8 from %ir.pa + 8)
-    VFPSPILLDx2 killed renamable $d4_d5x2, $sp :: (store 16 into %stack.1, align 8)
</span><span class="gi">+    VFPSPILLDx2 killed renamable $d7_d4x2, killed $lr :: (store 16 into %stack.0, align 8)
+    renamable $d7 = VLDRD renamable $r0, 0, 14 /* CC::al */, $noreg, implicit-def $d7_d4x2 :: (load 8 from %ir.pa)
+    renamable $d4 = VLDRD killed renamable $r0, 2, 14 /* CC::al */, $noreg, implicit killed $d7_d4x2, implicit-def $d7_d4x2 :: (load 8 from %ir.pa + 8)
+    VFPSPILLDx2 killed renamable $d7_d4x2, $sp :: (store 16 into %stack.1, align 8)
</span>     $r0 = MOVi 1, 14 /* CC::al */, $noreg, $noreg
     $r1 = MOVi 3, 14 /* CC::al */, $noreg, $noreg
     BL @foo, csr_aapcs, implicit-def dead $lr, implicit $sp, implicit $r0, implicit $r1, implicit-def $sp
     dead renamable $r0, dead renamable $r1 = VFPSETLEN 1, implicit-def $fpscr
     $lr = ADDri killed $sp, 16, 14 /* CC::al */, $noreg, $noreg
<span class="gd">-    renamable $d4_d5x2 = VFPRELOADDx2 killed $lr :: (load 16 from %stack.0, align 8)
-    renamable $d6_d7x2 = VFPRELOADDx2 $sp :: (load 16 from %stack.1, align 8)
-    renamable $d4_d5x2 = VADDDx2 killed renamable $d6_d7x2, killed renamable $d4_d5x2, 14 /* CC::al */, $noreg, implicit $fpscr
-    VSTRD renamable $d4, renamable $r4, 0, 14 /* CC::al */, $noreg :: (store 8 into %ir.pc)
-    VSTRD renamable $d5, killed renamable $r4, 2, 14 /* CC::al */, $noreg, implicit killed $d4_d5x2 :: (store 8 into %ir.pc + 8)
</span><span class="gi">+    renamable $d7_d4x2 = VFPRELOADDx2 killed $lr :: (load 16 from %stack.0, align 8)
+    renamable $d8_d9x2 = VFPRELOADDx2 $sp :: (load 16 from %stack.1, align 8)
+    renamable $d7_d4x2 = VADDDx2 killed renamable $d8_d9x2, killed renamable $d7_d4x2, 14 /* CC::al */, $noreg, implicit $fpscr
+    VSTRD renamable $d7, renamable $r4, 0, 14 /* CC::al */, $noreg :: (store 8 into %ir.pc)
+    VSTRD renamable $d4, killed renamable $r4, 2, 14 /* CC::al */, $noreg, implicit killed $d7_d4x2 :: (store 8 into %ir.pc + 8)
</span>     dead renamable $r0, dead renamable $r1 = VFPSETLEN 0, implicit-def $fpscr
     $sp = frame-destroy ADDri killed $sp, 32, 14 /* CC::al */, $noreg, $noreg
     $sp = frame-destroy LDMIA_RET $sp, 14 /* CC::al */, $noreg, def $r4, def $r5, def $r6, def $pc</code></pre></figure>

<p>The diff is a bit noisy: occurrences of physical registers <code class="language-plaintext highlighter-rouge">$d6_d7x2</code> are
replaced with the physical register <code class="language-plaintext highlighter-rouge">$d8_d9x2</code> and occurrences of the physical
register <code class="language-plaintext highlighter-rouge">$d4_d5x2</code> are replaced with the physical register <code class="language-plaintext highlighter-rouge">$d7_d4x2</code>. This
register is non-contiguous.</p>

<p>Now we can restart the code generation pipeline using the modified Machine IR
file, right before <code class="language-plaintext highlighter-rouge">arm-ldst-opt</code> (note the <code class="language-plaintext highlighter-rouge">-start-before</code> flag).</p>

<figure class="highlight"><pre><code class="language-diff" data-lang="diff"><span class="err">$</span> llc -mtriple armv6kz-unknown-linux-gnu -mattr=+vfp2  -o - test.mir \
      -start-before=arm-ldst-opt</code></pre></figure>

<p>Now the output looks like this:</p>

<figure class="highlight"><pre><code class="language-asm" data-lang="asm">test_vec:
	.fnstart
@ %bb.0:
	push	{r4, r5, r6, lr}
	sub	sp, sp, #32
	vldr	d7, [r1]
	add	lr, sp, #16
	vldr	d4, [r1, #8]
	mov	r1, #3
	vstr	d7, [lr]                        @ 8-byte Spill
	mov	r4, r2
	vstr	d4, [lr, #8]                    @ 8-byte Spill
	vldr	d7, [r0]
	vldr	d4, [r0, #8]
	mov	r0, #1
	vstr	d7, [sp]                        @ 8-byte Spill
	vstr	d4, [sp, #8]                    @ 8-byte Spill
	bl	foo
	vmrs	r1, fpscr
	mov	r0, #65536
	add	lr, sp, #16
	bic	r1, r1, #458752
	orr	r1, r1, r0
	vmsr	fpscr, r1
	vldr	d7, [lr]                        @ 8-byte Reload
	vldmia	sp, {d8, d9}                    @ 16-byte Reload
	vldr	d7, [lr, #8]                    @ 8-byte Reload
	vadd.f64	d7, d8, d7
	vstr	d7, [r4]
	vstr	d4, [r4, #8]
	vmrs	r1, fpscr
	bic	r1, r1, #458752
	vmsr	fpscr, r1
	add	sp, sp, #32
	pop	{r4, r5, r6, pc}</code></pre></figure>

<p>One observation that we could make here is that, ideally we should prefer not
to pick these non-consecutive registers. Both the spills and reloads that
involve them are costlier in number of instructions. This is something we could
influence in <code class="language-plaintext highlighter-rouge">ARMRegisterInfo.td</code>.</p>

<h2>Copies</h2>

<p>We mentioned above the compiler may have to introduce copies when removing SSA.
But the backend does not know how to do that.</p>

<p>Fortunately the ARM backend is very well implemented so adding this is
relatively easy to do in <code class="language-plaintext highlighter-rouge">ARMBaseInstrInfo.cpp</code></p>

<figure class="highlight"><figcaption>llvm/lib/Target/ARM/ARMBaseInstrInfo.cpp</figcaption><pre><code class="language-diff" data-lang="diff"><span class="p">@@ -979,6 +979,16 @@</span> void ARMBaseInstrInfo::copyPhysReg(MachineBasicBlock &amp;MBB,
     Opc = ARM::VMOVS;
     BeginIdx = ARM::ssub_0;
     SubRegs = 2;
<span class="gi">+  } else if (ARM::DPRx2RegClass.contains(DestReg, SrcReg) &amp;&amp;
+             Subtarget.hasVFP2Base()) {
+    Opc = ARM::VMOVD;
+    BeginIdx = ARM::dsub_len2_0;
+    SubRegs = 2;
+  } else if (ARM::SPRx4RegClass.contains(DestReg, SrcReg) &amp;&amp;
+             Subtarget.hasVFP2Base()) {
+    Opc = ARM::VMOVS;
+    BeginIdx = ARM::ssub_len4_0;
+    SubRegs = 4;
</span>   } else if (SrcReg == ARM::CPSR) {
     copyFromCPSR(MBB, I, DestReg, KillSrc, Subtarget);
     return;</code></pre></figure>

<p>The code already knows how to copy subregisters so we specify the instruction
we want to use, <code class="language-plaintext highlighter-rouge">vmovd</code> or <code class="language-plaintext highlighter-rouge">vmovs</code>, and how many subregisters are involved
from the first subregister.</p>

<h3>Results</h3>

<p>In order to force copies be emitted, we need to make sure our LLVM IR code
has control flow that mandates this.</p>

<p>The following LLVM IR causes this:</p>

<figure class="highlight"><figcaption>t_doubles_phi.ll</figcaption><pre><code class="language-llvm" data-lang="llvm"><span class="k">define</span> <span class="kt">void</span> <span class="vg">@test_vec</span><span class="p">(</span><span class="kt">i32</span> <span class="nv">%dis</span><span class="p">,</span>
                      <span class="p">&lt;</span><span class="m">2</span> <span class="p">x</span> <span class="kt">double</span><span class="p">&gt;</span> <span class="p">*</span><span class="nv">%pa</span><span class="p">,</span>
                      <span class="p">&lt;</span><span class="m">2</span> <span class="p">x</span> <span class="kt">double</span><span class="p">&gt;</span> <span class="p">*</span><span class="nv">%pb</span><span class="p">,</span>
                      <span class="p">&lt;</span><span class="m">2</span> <span class="p">x</span> <span class="kt">double</span><span class="p">&gt;</span> <span class="p">*</span><span class="nv">%pc</span><span class="p">)</span> <span class="p">{</span>
  <span class="nv">%a</span> <span class="p">=</span> <span class="k">load</span> <span class="p">&lt;</span><span class="m">2</span> <span class="p">x</span> <span class="kt">double</span><span class="p">&gt;,</span> <span class="p">&lt;</span><span class="m">2</span> <span class="p">x</span> <span class="kt">double</span><span class="p">&gt;*</span> <span class="nv">%pa</span>
  <span class="nv">%b</span> <span class="p">=</span> <span class="k">load</span> <span class="p">&lt;</span><span class="m">2</span> <span class="p">x</span> <span class="kt">double</span><span class="p">&gt;,</span> <span class="p">&lt;</span><span class="m">2</span> <span class="p">x</span> <span class="kt">double</span><span class="p">&gt;*</span> <span class="nv">%pb</span>
  <span class="nv">%m</span> <span class="p">=</span> <span class="k">icmp</span> <span class="k">slt</span> <span class="kt">i32</span> <span class="nv">%dis</span><span class="p">,</span> <span class="m">4</span>
  <span class="k">br</span> <span class="kt">i1</span> <span class="nv">%m</span><span class="p">,</span> <span class="kt">label</span> <span class="nv">%block1</span><span class="p">,</span> <span class="kt">label</span> <span class="nv">%block2</span>
<span class="nl">block1:</span>
  <span class="nv">%x</span> <span class="p">=</span> <span class="k">fadd</span> <span class="p">&lt;</span><span class="m">2</span> <span class="p">x</span> <span class="kt">double</span><span class="p">&gt;</span> <span class="nv">%a</span><span class="p">,</span> <span class="nv">%b</span>
  <span class="k">br</span> <span class="kt">label</span> <span class="nv">%block3</span>
<span class="nl">block2:</span>
  <span class="nv">%y</span> <span class="p">=</span> <span class="k">fmul</span> <span class="p">&lt;</span><span class="m">2</span> <span class="p">x</span> <span class="kt">double</span><span class="p">&gt;</span> <span class="nv">%a</span><span class="p">,</span> <span class="nv">%b</span>
  <span class="k">br</span> <span class="kt">label</span> <span class="nv">%block3</span>
<span class="nl">block3:</span>
  <span class="nv">%p</span> <span class="p">=</span> <span class="k">phi</span> <span class="p">&lt;</span><span class="m">2</span> <span class="p">x</span> <span class="kt">double</span><span class="p">&gt;</span> <span class="p">[</span><span class="nv">%x</span><span class="p">,</span> <span class="nv">%block1</span><span class="p">],</span> <span class="p">[</span><span class="nv">%y</span><span class="p">,</span> <span class="nv">%block2</span><span class="p">]</span>
  <span class="k">store</span> <span class="p">&lt;</span><span class="m">2</span> <span class="p">x</span> <span class="kt">double</span><span class="p">&gt;</span> <span class="nv">%p</span><span class="p">,</span> <span class="p">&lt;</span><span class="m">2</span> <span class="p">x</span> <span class="kt">double</span><span class="p">&gt;</span> <span class="p">*</span><span class="nv">%pc</span>
  <span class="k">ret</span> <span class="kt">void</span>
<span class="p">}</span></code></pre></figure>

<p>Basically we check if the first parameter <code class="language-plaintext highlighter-rouge">%dis</code> is larger that 4. If it is we
add vectors <code class="language-plaintext highlighter-rouge">%a</code> and <code class="language-plaintext highlighter-rouge">%b</code> (<code class="language-plaintext highlighter-rouge">block1</code>). Otherwise we multiply them (<code class="language-plaintext highlighter-rouge">block2</code>).
This is the value we store in the pointer <code class="language-plaintext highlighter-rouge">*%pc</code> (<code class="language-plaintext highlighter-rouge">block3</code>). The value, however
flows in from the two blocks, hence a <code class="language-plaintext highlighter-rouge">phi</code> instruction appears to merge the two
incoming values. The merged value <code class="language-plaintext highlighter-rouge">%p</code> is the one stored.</p>

<p>We can look at the Machine IR right before the pass <code class="language-plaintext highlighter-rouge">postrapseudos</code>, which is
used to expand the generic pseudo instructions used by the Register Allocator
(<code class="language-plaintext highlighter-rouge">ra</code>).  Those pseudos include a generic <code class="language-plaintext highlighter-rouge">COPY</code> instruction.</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="nv">$ </span>llc <span class="nt">-mtriple</span> armv6kz-unknown-linux-gnu <span class="nt">-mattr</span><span class="o">=</span>+vfp2  <span class="nt">-o</span> copy.mir <span class="se">\</span>
      t_doubles_phi.ll  <span class="nt">-stop-before</span><span class="o">=</span>postrapseudos <span class="nt">-simplify-mir</span></code></pre></figure>

<figure class="highlight"><figcaption>copy.mir</figcaption><pre><code class="language-asm" data-lang="asm"><table class="rouge-table"><tbody><tr><td class="gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
</pre></td><td class="code"><pre>body:             |
  bb.0.block3:
    liveins: $r0, $r1, $r2, $r3, $d8, $d9
  
    $sp = frame-setup VSTMDDB_UPD $sp, 14 /* CC::al */, $noreg, killed $d8, killed $d9
    frame-setup CFI_INSTRUCTION def_cfa_offset 16
    frame-setup CFI_INSTRUCTION offset $d9, -8
    frame-setup CFI_INSTRUCTION offset $d8, -16
    renamable $d4 = VLDRD renamable $r2, 0, 14 /* CC::al */, $noreg, implicit-def $d4_d5x2 :: (load 8 from %ir.pb)
    renamable $d5 = VLDRD killed renamable $r2, 2, 14 /* CC::al */, $noreg, implicit killed $d4_d5x2, implicit-def $d4_d5x2 :: (load 8 from %ir.pb + 8)
    renamable $d8 = VLDRD renamable $r1, 0, 14 /* CC::al */, $noreg, implicit-def $d8_d9x2 :: (load 8 from %ir.pa)
    renamable $d9 = VLDRD killed renamable $r1, 2, 14 /* CC::al */, $noreg, implicit killed $d8_d9x2, implicit-def $d8_d9x2 :: (load 8 from %ir.pa + 8)
    dead renamable $r1, dead renamable $r2 = VFPSETLEN 1, implicit-def $fpscr
    renamable $d6_d7x2 = VMULDx2 renamable $d8_d9x2, renamable $d4_d5x2, 14 /* CC::al */, $noreg, implicit $fpscr
    renamable $d4_d5x2 = VADDDx2 killed renamable $d8_d9x2, killed renamable $d4_d5x2, 14 /* CC::al */, $noreg, implicit $fpscr
    CMPri killed renamable $r0, 4, 14 /* CC::al */, $noreg, implicit-def $cpsr
    Bcc %bb.2, 11 /* CC::lt */, killed $cpsr
  
  bb.1.select.false:
    liveins: $r3, $d6_d7x2
  
    renamable $d4_d5x2 = COPY killed renamable $d6_d7x2
  
  bb.2.select.end:
    liveins: $r3, $d4_d5x2
  
    VSTRD renamable $d4, renamable $r3, 0, 14 /* CC::al */, $noreg :: (store 8 into %ir.pc)
    VSTRD renamable $d5, killed renamable $r3, 2, 14 /* CC::al */, $noreg, implicit killed $d4_d5x2 :: (store 8 into %ir.pc + 8)
    dead renamable $r0, dead renamable $r1 = VFPSETLEN 0, implicit-def $fpscr
    $sp = frame-destroy VLDMDIA_UPD $sp, 14 /* CC::al */, $noreg, def $d8, def $d9
    BX_RET 14 /* CC::al */, $noreg
</pre></td></tr></tbody></table></code></pre></figure>

<p>If you look closely at the code, you can see the compiler has changed the code
in a way that it especulatively executes the <code class="language-plaintext highlighter-rouge">fadd</code> and the <code class="language-plaintext highlighter-rouge">fmul</code> (look for
<code class="language-plaintext highlighter-rouge">VMULDx2</code> and <code class="language-plaintext highlighter-rouge">VADDDx2</code> instructions in lines 14 and 15) in the entry block
(shown as <code class="language-plaintext highlighter-rouge">bb.0.block3</code>, but the relevant bit is <code class="language-plaintext highlighter-rouge">bb.0</code>). Each operation uses a
different register (<code class="language-plaintext highlighter-rouge">$d4_d5x2</code> and <code class="language-plaintext highlighter-rouge">$d6_d7x2</code>) and one of the registers
(<code class="language-plaintext highlighter-rouge">$d4_d5x2</code>) is the one that ends being stored in the final block
(<code class="language-plaintext highlighter-rouge">bb.2.select.end</code>, lines 27 and 28).</p>

<p>Then the comparison happens and if turns out false (block <code class="language-plaintext highlighter-rouge">bb.1.select.false</code>,
lines 19 to 22) we copy the contents of <code class="language-plaintext highlighter-rouge">$d6_d7x2</code> (line 22), which contains
the multiplication result, into <code class="language-plaintext highlighter-rouge">$d4_d5x2</code>.</p>

<p>If we look at the generated assembly, we see the copies we explicitly introduced.</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="nv">$ </span>llc <span class="nt">-mtriple</span> armv6kz-unknown-linux-gnu <span class="nt">-mattr</span><span class="o">=</span>+vfp2  <span class="nt">-o</span> - t_doubles_phi.ll</code></pre></figure>

<figure class="highlight"><pre><code class="language-asm" data-lang="asm">test_vec:
	.fnstart
@ %bb.0:                                @ %block3
	vpush	{d8, d9}
	vldmia	r1, {d8, d9}
	mov	r1, #65536
	cmp	r0, #4
	vldmia	r2, {d4, d5}
	vmrs	r2, fpscr
	bic	r2, r2, #458752
	orr	r2, r2, r1
	vmsr	fpscr, r2
	vmul.f64	d6, d8, d4
	vadd.f64	d4, d8, d4
	blt	.LBB0_2
@ %bb.1:                                @ %select.false
	vmov.f64	d4, d6
	vmov.f64	d5, d7
.LBB0_2:                                @ %select.end
	vstmia	r3, {d4, d5}
	vmrs	r1, fpscr
	bic	r1, r1, #458752
	vmsr	fpscr, r1
	vpop	{d8, d9}
	bx	lr</code></pre></figure>

<p>And this is all for this installment. In the next one we will make enough
changes to the compiler so we can convince the existing loop vectorizer of LLVM
that it can vectorize some simple codes in VFPv2.</p>

  </div>

</article>

<div class="pagination">

  <a class="previous" href="/2021/07/11/raspberry-vectors-part-6/">&laquo; Fun with vectors in the Raspberry Pi 1 - Part 6</a>


</div>



      </div>
    </main>

    <footer class="site-footer">

  <div class="wrapper">

    <p>
      

Powered by <a href="https://jekyllrb.com">Jekyll</a>. Theme based on <a href="https://github.com/yous/whiteglass">whiteglass</a>
<br>
Subscribe via <a href="https://thinkingeek.com/feed.xml">RSS</a>

    </p>

  </div>

</footer>


  </body>

</html>
